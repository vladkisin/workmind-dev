{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import pandas as pd\n",
    "df = pd.read_csv('/kaggle/input/gpt-dataset/interventions_eval_gpt4o.csv') # pd.read_csv('/kaggle/input/gpt-dataset/interventions_on_glassdoor_eval_gpt4o.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from kaggle_secrets import UserSecretsClient\n",
    "user_secrets = UserSecretsClient()\n",
    "PAT = user_secrets.get_secret(\"pat\")\n",
    "\n",
    "\n",
    "GITHUB_USERNAME = \"vladkisin\"\n",
    "REPO_NAME = \"workmind-dev\"\n",
    "REPO_URL = f\"https://{GITHUB_USERNAME}:{PAT}@github.com/{GITHUB_USERNAME}/{REPO_NAME}.git\"\n",
    "os.system(f\"git clone {REPO_URL}\")\n",
    "os.chdir(\"/kaggle/working/workmind-dev\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! pip install -U -r requirements.txt --quiet\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import wandb\n",
    "wandb.login(key=user_secrets.get_secret(\"wandb_pat\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from generators.interventions import InterventionGenerator\n",
    "from experiment.wandb.interventions import InterventionExperiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "anchor = df['intervention'].tolist()\n",
    "input_texts = [text if isinstance(text, list) else [text] for text in df['texts'].apply(eval).tolist()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "system_prompt = \"\"\"\n",
    "You are an advanced text analysis assistant. Your task is to:\n",
    "- Read the provided {entity}.\n",
    "- Determine why the content indicates dissatisfaction or frustration. Most likely it does as it was identified by a sentiment analysis engine.\n",
    "- If dissatisfaction is detected:\n",
    "- Summarize the core issues clearly.\n",
    "- Propose concise short-term and long-term HR interventions.\n",
    "- If no dissatisfaction is detected, simply indicate that there is no frustration.\n",
    "- Output the response in a structured format:\n",
    "    0. Dissatisfaction detected: [Yes/No]\n",
    "    1. Dissatisfaction reason: [Brief summary]\n",
    "    2. Interventions:\n",
    "        a) Short term: [Actionable recommendations]\n",
    "        b) Long term: [Actionable recommendations]\n",
    "\"\"\"\n",
    "\n",
    "user_prompt = \"\"\"\n",
    "Please analyze the following {entity} and:\n",
    "1. Check if there is any dissatisfaction or frustration expressed.\n",
    "2. If so, identify the main reasons for the employeeâ€™s frustration.\n",
    "3. Summarize these concerns briefly and clearly.\n",
    "4. Recommend actionable short-term and long-term HR interventions. Be clear and concise.\n",
    "If there are certainly no signs of dissatisfaction are found, just indicate \"Dissatisfaction detected: No\" and stop generation.\n",
    "\n",
    "{entity}:\n",
    "{data}\n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PROJECT_NAME = \"workmind-interventions\"\n",
    "\n",
    "for model_name in ['microsoft/Phi-3-mini-4k-instruct',\n",
    "                   'tiiuae/Falcon3-7B-Instruct', \n",
    "                   'Qwen/Qwen2.5-7B-Instruct']:\n",
    "    intervention_generator = InterventionGenerator( \n",
    "                     model_name=model_name,\n",
    "                     max_input_tokens=1024,\n",
    "                     max_output_tokens=512,\n",
    "                     batch_size=1,\n",
    "                     load_in_8bit=False,\n",
    "                     load_in_4bit=True,\n",
    "                     entity='email(s)',\n",
    "                     system_prompt=system_prompt,\n",
    "                     user_prompt=user_prompt\n",
    "    )\n",
    "    \n",
    "    with InterventionExperiment(intervention_generator, model_name,  project_name=PROJECT_NAME) as exp:\n",
    "        exp.evaluate(input_texts, anchor)\n",
    "    del intervention_generator\n",
    "    torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [
    {
     "datasetId": 6505548,
     "sourceId": 10696424,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30840,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
