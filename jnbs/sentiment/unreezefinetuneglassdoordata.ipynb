{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "df = pd.read_csv(\"/kaggle/input/glassdoor-job-reviews/glassdoor_reviews.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from kaggle_secrets import UserSecretsClient\n",
    "user_secrets = UserSecretsClient()\n",
    "PAT = user_secrets.get_secret(\"pat\")\n",
    "\n",
    "\n",
    "GITHUB_USERNAME = \"vladkisin\"\n",
    "REPO_NAME = \"workmind-dev\"\n",
    "REPO_URL = f\"https://{GITHUB_USERNAME}:{PAT}@github.com/{GITHUB_USERNAME}/{REPO_NAME}.git\"\n",
    "os.system(f\"git clone {REPO_URL}\")\n",
    "os.chdir(\"/kaggle/working/workmind-dev\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "! pip install -U -r requirements.txt --quiet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from workmind.data_processing.utils import preprocess_and_split_gd\n",
    "train_df, val_df, test_df = preprocess_and_split_gd(df)\n",
    "\n",
    "\n",
    "print(f\"Train size: {len(train_df)}\")\n",
    "print(f\"Validation size: {len(val_df)}\")\n",
    "print(f\"Test size: {len(test_df)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import wandb\n",
    "wandb.login(key=user_secrets.get_secret(\"wandb_pat\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from datasets import Dataset\n",
    "from workmind.tuners.partial import PartiallyUnfrozenClsFineTuner\n",
    "from transformers import (\n",
    "    AutoConfig,\n",
    "    AutoTokenizer,\n",
    "    AutoModel,\n",
    "    TrainingArguments,\n",
    "    Trainer\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "model_name = \"roberta-large\"\n",
    "\n",
    "train_dataset = Dataset.from_dict(train_df.sample(frac=0.3)[[\"text\", \"label\"]].to_dict(orient=\"list\"))\n",
    "eval_dataset = Dataset.from_dict(val_df[[\"text\", \"label\"]].sample(1500).to_dict(orient=\"list\"))\n",
    "\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "\n",
    "def preprocess_data(batch):\n",
    "    return tokenizer(batch[\"text\"], padding=\"max_length\", truncation=True, max_length=min(tokenizer.model_max_length, 1024))\n",
    "\n",
    "train_dataset = train_dataset.map(preprocess_data, batched=True)\n",
    "eval_dataset = eval_dataset.map(preprocess_data, batched=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from huggingface_hub import login\n",
    "\n",
    "login(token=user_secrets.get_secret(\"hf_pat\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "**Fine-tune**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "id2label = {0: \"negative\", 1: \"neutral\", 2: \"positive\"}\n",
    "tuner = PartiallyUnfrozenClsFineTuner(\n",
    "    model_name_or_path=model_name,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=eval_dataset,\n",
    "    tokenizer=tokenizer,\n",
    "    layers_to_unfreeze=(\"layer.21\", \"layer.22\", \"layer.23\", \"classifier\"),\n",
    "    learning_rate=1e-4,\n",
    "    num_train_epochs=1,\n",
    "    train_batch_size=16,\n",
    "            val_batch_size=16\n",
    ")\n",
    "tuner.prepare_model()\n",
    "tuner.train(trainer_class=Trainer)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "repo_name = f\"uladzislauk/{model_name}-unfreeze-ft-glassdoor-60k\"\n",
    "\n",
    "tuner.model.push_to_hub(repo_name)\n",
    "tokenizer.push_to_hub(repo_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "**Evaluate on the same dataset**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from workmind.analyzers.sentiment.classification import ClassificationSentimentAnalyzer\n",
    "from workmind.analyzers.constants import BaseSentiment\n",
    "from workmind.experiment.wandb.sentiment import SentimentExperiment\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "y_glassdoor = test_df[\"recommend\"].map({\"v\": \"positive\", \"x\": \"negative\", \"o\": \"neutral\"}).tolist()\n",
    "reviews = test_df[\"review\"].tolist()\n",
    "PROJECT_NAME = \"workmind-glassdoor\"\n",
    "\n",
    "\n",
    "analyzer = ClassificationSentimentAnalyzer(\n",
    "    model_name=\"uladzislauk/roberta-base-unfreeze-ft-glassdoor-60k\",\n",
    "    class_labels=[BaseSentiment.NEGATIVE,\n",
    "                  BaseSentiment.NEUTRAL,\n",
    "                  BaseSentiment.POSITIVE], \n",
    "    batch_size=16, \n",
    "    hypothesis_template=None\n",
    ")\n",
    "\n",
    "with SentimentExperiment(\n",
    "    analyzer, \n",
    "    f\" unfrozen 3 layers on 60k Glassdoor 1 epoch for roberta-base\" + \" on Glassdoor Data\", \n",
    "    y_glassdoor,\n",
    "    project_name=PROJECT_NAME\n",
    ") as experiment:\n",
    "    experiment.evaluate(reviews)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "**Evaluate cross-dataset**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "gpt_df = pd.read_csv(\"/kaggle/input/gpt-dataset/gpt_dataset.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "gpt_emails = gpt_df[\"text\"].tolist()\n",
    "y_gpt_email = gpt_df[\"sentiment_label\"].tolist()\n",
    "user_ids = gpt_df[\"user_id\"].tolist()\n",
    "PROJECT_NAME=\"workmind-email-data\"\n",
    "\n",
    "analyzer = ClassificationSentimentAnalyzer(\n",
    "    model_name=\"uladzislauk/roberta-base-unfreeze-ft-glassdoor-60k\",\n",
    "    class_labels=[BaseSentiment.NEGATIVE,\n",
    "                  BaseSentiment.NEUTRAL,\n",
    "                  BaseSentiment.POSITIVE], \n",
    "    batch_size=16, \n",
    "    hypothesis_template=None\n",
    ")\n",
    "\n",
    "with SentimentExperiment(\n",
    "    analyzer, \n",
    "    f\" unfrozen 3 layers on 60k Glassdoor 1 epoch for roberta-base\" + \" on ChatGPT-o1 Generated Data\", \n",
    "    y_gpt_email,\n",
    "    project=PROJECT_NAME\n",
    ") as experiment:\n",
    "    experiment.evaluate(gpt_emails, user_ids)"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [
    {
     "datasetId": 805946,
     "sourceId": 1381318,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 2545470,
     "sourceId": 9631506,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 4677933,
     "sourceId": 9631516,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 6505548,
     "sourceId": 10696424,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30840,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}